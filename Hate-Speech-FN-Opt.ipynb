{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does annotation bias in training datasets affect the accuracy of a given hate speech classifier?\n",
    "\n",
    "Baseline: Binary Classifier (Hate / Not Hate) Support Vector Machine\n",
    "\n",
    "Experiment with different annotated hate speech datasets\n",
    "\n",
    "Report on ethics of defining hate speech\n",
    "Importance on increasing accuracy, burat what cost does this increase in accuracy come at?\n",
    "Does the computer recognize that some people are more sensitive than others?\n",
    "The computer is analyzing patterns in a given dataset to conclude its own definition of hate speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import logging\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"dataset.csv\")\n",
    "df.drop_duplicates()\n",
    "hate_speech = df.query('Class==\"hate\"').copy().reset_index()\n",
    "test_hate = hate_speech[:162].copy()\n",
    "data_hate = hate_speech[162:3009].copy()\n",
    "\n",
    "non_hate_speech = df.query('Class==\"none\"').copy().reset_index()\n",
    "test_non = non_hate_speech[:162].copy()\n",
    "data_none = non_hate_speech[162:3009].copy()\n",
    "\n",
    "test_data = pd.merge(test_hate, test_non, how='outer').sample(frac=1).reset_index()\n",
    "data = pd.merge(data_hate, data_none, how='outer').sample(frac=1).reset_index()\n",
    "df = pd.merge(data, test_data, how='outer').copy()\n",
    "\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processing(raw_tweet):\n",
    "    letters_only=re.sub(\"[^a-zA-Z]\",\" \",raw_tweet)\n",
    "    words=letters_only.lower().split()\n",
    "    stops=set(stopwords.words(\"english\"))\n",
    "    m_w=[w for w in words if not w in stops]\n",
    "    return (\" \".join(m_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tweets=data[\"Tweets\"].size\n",
    "clean_tweet=[]\n",
    "for i in range(0,num_tweets):\n",
    "    clean_tweet.append(tweet_processing(data[\"Tweets\"][i]))\n",
    "data[\"Tweets\"]=clean_tweet \n",
    "\n",
    "\n",
    "num_tweets_test=test_data[\"Tweets\"].size\n",
    "clean_tweet_test=[]\n",
    "for i in range(0,num_tweets_test):\n",
    "    clean_tweet_test.append(tweet_processing(test_data[\"Tweets\"][i]))\n",
    "test_data[\"Tweets\"]=clean_tweet_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_svm, Y_train, Y_test_svm = train_test_split(df.Tweets, df.Class, test_size=0.2)\n",
    "\n",
    "train_dict = {}\n",
    "for tweet_class in Y_train:\n",
    "    if tweet_class in train_dict:\n",
    "        train_dict[tweet_class] += 1\n",
    "    else:\n",
    "        train_dict[tweet_class] = 1\n",
    "        \n",
    "test_dict = {}  \n",
    "for tweet_class in Y_test_svm:\n",
    "    if tweet_class in test_dict:\n",
    "        test_dict[tweet_class] += 1\n",
    "    else:\n",
    "        test_dict[tweet_class] = 1\n",
    "\n",
    "data_dict = {\"Train Data Split\" : {\"Hate Speech\" : (1 - train_dict['none'] / len(Y_train)) * 100, \"Non-Hate Speech\" : (train_dict['none'] / len(Y_train) * 100)},\n",
    "            \"Test Data Split\" : {\"Hate Speech\" : (1 - test_dict['none'] / len(Y_test_svm)) * 100, \"Non-Hate Speech\" : (test_dict['none'] / len(Y_test_svm) *100)}}\n",
    "\n",
    "ds = pd.DataFrame(data_dict)\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Testing\n",
      "Accuracy:  0.8637873754152824\n",
      "Precision: 0.8652263156781006 \n",
      "Recall: 0.8637873754152824 \n",
      "F1 Score: 0.8637332422311453\n"
     ]
    }
   ],
   "source": [
    "vectorizer=CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,stop_words = None,max_features = 5000)\n",
    "\n",
    "train_data_features=vectorizer.fit_transform(X_train)\n",
    "train_data_features=train_data_features.toarray()\n",
    "\n",
    "test_data_features=vectorizer.transform(X_test_svm)\n",
    "test_data_features=test_data_features.toarray()\n",
    "\n",
    "#SVM with linear kernel\n",
    "clf=svm.SVC(kernel='linear',C=1.0)\n",
    "print (\"Training\")\n",
    "clf.fit(train_data_features,Y_train)\n",
    "\n",
    "print (\"Testing\")\n",
    "predicted=clf.predict(test_data_features)\n",
    "accuracy=np.mean(predicted==Y_test_svm)\n",
    "print (\"Accuracy: \",accuracy)\n",
    "score_svm=precision_recall_fscore_support(Y_test_svm, predicted, average='weighted')\n",
    "print(\"Precision:\", score_svm[0], \"\\nRecall:\", score_svm[1], \"\\nF1 Score:\", score_svm[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 41.52823920265781 FN = 7.392026578073089 \n",
      "TN  = 45.51495016611295 FP = 5.564784053156146\n"
     ]
    }
   ],
   "source": [
    "newDict = {\"Tweets\" : X_test_svm, \"Actual\" : Y_test_svm, \"Predicted\" : predicted}\n",
    "\n",
    "df2 = pd.DataFrame(newDict).reset_index()\n",
    "\n",
    "true_pos = df2.query('Actual == \"hate\" and Actual == Predicted').copy().reset_index()\n",
    "true_neg = df2.query('Actual == \"none\" and Actual == Predicted').copy().reset_index()\n",
    "false_neg = df2.query('Actual == \"hate\" and Actual != Predicted').copy().reset_index()\n",
    "false_pos = df2.query('Actual == \"none\" and Actual != Predicted').copy().reset_index()\n",
    "\n",
    "print(\"TP =\", len(true_pos) / len(df2) * 100, \"FN =\", len(false_neg) / len(df2) * 100, \"\\nTN  =\", len(true_neg) / len(df2) * 100, \"FP =\", len(false_pos) / len(df2) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Re-Annotation Algorithm Implementation and Application\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "params: Size of Dataset, Percentage of False Negatives from Orig Model Run\n",
    "\n",
    "{   \n",
    "    Compute number of Tweets to re-annotate by using the percentage of FN on Size of DataSet\n",
    "    num = Dataset * FN-Percentage\n",
    "    randomly sample num not hate from original dataset \n",
    "    re-annotate from not hate to hate\n",
    "}\n",
    "\n",
    "Is hate predicts its not\n",
    "\n",
    "the rules for what is not over prioritize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Re-Annotations: 6 : 6018\n",
      "65    @TicklishQuill It's actually only one face.  I...\n",
      "85    RT @TwoThug4U: @YesYoureSexist but honestly st...\n",
      "76    @dgbattaglia Saw this this morning... http://t...\n",
      "41    @GRIMACHU @AliRadicali @avacadosoup  Sealionin...\n",
      "46    @jkronenwetter18 I'm sure the commentators you...\n",
      "77    @AJKauffman @CocaCola Yeah, if there's one thi...\n",
      "Name: Tweets, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int( len(false_neg) / len(df2) * len(false_neg))\n",
    "\n",
    "print(\"Number of Re-Annotations: \" + str(n) + \" : \" + str(len(df)))\n",
    "\n",
    "false_tweets = false_neg.sample(n=n).Tweets\n",
    "print(false_tweets)\n",
    "t = []\n",
    "for x in false_tweets:\n",
    "    t.append(x)\n",
    "t = pd.Series(t)\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = df.copy()\n",
    "\n",
    "copy_df.query('Tweets in @t').replace('hate', 'none')\n",
    "\n",
    "fileName = \"random_reannotated_\" + \".csv\"\n",
    "copy_df.to_csv(fileName)\n",
    "    \n",
    "# Re-Annotate Data\n",
    "r_df = pd.read_csv(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>User Id</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>779</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>507035960325177000</td>\n",
       "      <td>RT @tylerxclark: I'm not sexist but have you e...</td>\n",
       "      <td>930620467</td>\n",
       "      <td>YesYoureSexist</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2891</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>469139702549729000</td>\n",
       "      <td>@Mike_Antoniou15 \"I feel like\" = \"I have no ev...</td>\n",
       "      <td>930620467</td>\n",
       "      <td>YesYoureSexist</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>678</td>\n",
       "      <td>1165</td>\n",
       "      <td>1165</td>\n",
       "      <td>489515039141810000</td>\n",
       "      <td>RT @Justin_DvG: @UberFacts this is why DC &amp;gt;...</td>\n",
       "      <td>930620467</td>\n",
       "      <td>YesYoureSexist</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>981</td>\n",
       "      <td>1917</td>\n",
       "      <td>1917</td>\n",
       "      <td>546362209127759000</td>\n",
       "      <td>RT @RykerDomz When a woman gets in a wreck I'm...</td>\n",
       "      <td>930620467</td>\n",
       "      <td>YesYoureSexist</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>835</td>\n",
       "      <td>1543</td>\n",
       "      <td>1543</td>\n",
       "      <td>517430515616731000</td>\n",
       "      <td>I have a hint for you in my usename @et_tweet_...</td>\n",
       "      <td>930620467</td>\n",
       "      <td>YesYoureSexist</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index  Unnamed: 0            Tweet Id  \\\n",
       "0      779   1399        1399  507035960325177000   \n",
       "1     2891    908         908  469139702549729000   \n",
       "2      678   1165        1165  489515039141810000   \n",
       "3      981   1917        1917  546362209127759000   \n",
       "4      835   1543        1543  517430515616731000   \n",
       "\n",
       "                                              Tweets    User Id  \\\n",
       "0  RT @tylerxclark: I'm not sexist but have you e...  930620467   \n",
       "1  @Mike_Antoniou15 \"I feel like\" = \"I have no ev...  930620467   \n",
       "2  RT @Justin_DvG: @UberFacts this is why DC &gt;...  930620467   \n",
       "3  RT @RykerDomz When a woman gets in a wreck I'm...  930620467   \n",
       "4  I have a hint for you in my usename @et_tweet_...  930620467   \n",
       "\n",
       "      Screen Name Class  \n",
       "0  YesYoureSexist  hate  \n",
       "1  YesYoureSexist  none  \n",
       "2  YesYoureSexist  hate  \n",
       "3  YesYoureSexist  hate  \n",
       "4  YesYoureSexist  hate  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_tweets=data[\"Tweets\"].size\n",
    "clean_tweet=[]\n",
    "for i in range(0,num_tweets):\n",
    "    clean_tweet.append(tweet_processing(data[\"Tweets\"][i]))\n",
    "data[\"Tweets\"]=clean_tweet \n",
    "\n",
    "\n",
    "num_tweets_test=test_data[\"Tweets\"].size\n",
    "clean_tweet_test=[]\n",
    "for i in range(0,num_tweets_test):\n",
    "    clean_tweet_test.append(tweet_processing(test_data[\"Tweets\"][i]))\n",
    "test_data[\"Tweets\"]=clean_tweet_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train Data Split': {'Hate Speech': 50.27004570004154, 'Non-Hate Speech': 49.72995429995846}, 'Test Data Split': {'Hate Speech': 48.9202657807309, 'Non-Hate Speech': 51.0797342192691}}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test_svm, Y_train, Y_test_svm = train_test_split(df.Tweets, df.Class, test_size=0.2)\n",
    "\n",
    "train_dict = {}\n",
    "for tweet_class in Y_train:\n",
    "    if tweet_class in train_dict:\n",
    "        train_dict[tweet_class] += 1\n",
    "    else:\n",
    "        train_dict[tweet_class] = 1\n",
    "        \n",
    "test_dict = {}  \n",
    "for tweet_class in Y_test_svm:\n",
    "    if tweet_class in test_dict:\n",
    "        test_dict[tweet_class] += 1\n",
    "    else:\n",
    "        test_dict[tweet_class] = 1\n",
    "\n",
    "data_dict = {\"Train Data Split\" : {\"Hate Speech\" : (1 - train_dict['none'] / len(Y_train)) * 100, \"Non-Hate Speech\" : (train_dict['none'] / len(Y_train) * 100)},\n",
    "            \"Test Data Split\" : {\"Hate Speech\" : (1 - test_dict['none'] / len(Y_test_svm)) * 100, \"Non-Hate Speech\" : (test_dict['none'] / len(Y_test_svm) *100)}}\n",
    "\n",
    "ds = pd.DataFrame(data_dict)\n",
    "\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Testing\n",
      "Accuracy:  0.8704318936877077\n",
      "Precision: 0.8708256944295546 \n",
      "Recall: 0.8704318936877077 \n",
      "F1 Score: 0.8703373571121347\n"
     ]
    }
   ],
   "source": [
    "vectorizer=CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,stop_words = None,max_features = 5000)\n",
    "\n",
    "train_data_features=vectorizer.fit_transform(X_train)\n",
    "train_data_features=train_data_features.toarray()\n",
    "\n",
    "test_data_features=vectorizer.transform(X_test_svm)\n",
    "test_data_features=test_data_features.toarray()\n",
    "\n",
    "#SVM with linear kernel\n",
    "clf=svm.SVC(kernel='linear',C=1.0)\n",
    "print (\"Training\")\n",
    "clf.fit(train_data_features,Y_train)\n",
    "\n",
    "print (\"Testing\")\n",
    "predicted=clf.predict(test_data_features)\n",
    "accuracy=np.mean(predicted==Y_test_svm)\n",
    "print (\"Accuracy: \",accuracy)\n",
    "score_svm=precision_recall_fscore_support(Y_test_svm, predicted, average='weighted')\n",
    "print(\"Precision:\", score_svm[0], \"\\nRecall:\", score_svm[1], \"\\nF1 Score:\", score_svm[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 41.52823920265781 FN = 7.392026578073089 \n",
      "TN  = 45.51495016611295 FP = 5.564784053156146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1204"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDict = {\"Tweets\" : X_test_svm, \"Actual\" : Y_test_svm, \"Predicted\" : predicted}\n",
    "\n",
    "df2 = pd.DataFrame(newDict).reset_index()\n",
    "\n",
    "true_pos = df2.query('Actual == \"hate\" and Actual == Predicted').copy().reset_index()\n",
    "true_neg = df2.query('Actual == \"none\" and Actual == Predicted').copy().reset_index()\n",
    "false_neg = df2.query('Actual == \"hate\" and Actual != Predicted').copy().reset_index()\n",
    "false_pos = df2.query('Actual == \"none\" and Actual != Predicted').copy().reset_index()\n",
    "\n",
    "print(\"TP =\", len(true_pos) / len(df2) * 100, \"FN =\", len(false_neg) / len(df2) * 100, \"\\nTN  =\", len(true_neg) / len(df2) * 100, \"FP =\", len(false_pos) / len(df2) * 100)\n",
    "\n",
    "len(df2) * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello {'H': 'ELL', 'J': 'RII'}\n"
     ]
    }
   ],
   "source": [
    "d = {\"H\" : \"ELL\", \"J\" : \"RII\"}\n",
    "\n",
    "print(\"Hello \" + str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (32614955.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [18]\u001b[1;36m\u001b[0m\n\u001b[1;33m    else\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "f = pd.DataFrame()\n",
    "if f.empty:\n",
    "    f = pd.DataFrame(d)\n",
    "else\n",
    "    f.merge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of DataFrame: 6000 \n",
      "Percentage of Hate Tweets: 0.5 \n",
      "Percentage of non-Hate Tweets: 0.5\n",
      "\n",
      "Length of Train Split: 4800 \n",
      "Percentage of Hate Tweets: 0.5 \n",
      "Percentage of non-Hate Tweets: 0.5\n",
      "\n",
      "Length of Test Split: 1200 \n",
      "Percentage of Hate Tweets: 0.5 \n",
      "Percentage of non-Hate Tweets: 0.5\n",
      "\n",
      "Training SVM...\n",
      "Testing SVM...\n",
      "\n",
      "Precision: 0.8066519236071847 \n",
      "Recall: 0.8058333333333333 \n",
      "F1 Score: 0.8057036675170026\n",
      "\n",
      "Will randomly re-annotate: 11.0% of hate speech\n",
      "Will randomly re-annotate: 8.416666666666666% of non-hate speech\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Loading Data\n",
    "df = pd.read_csv(\"dataset.csv\").drop_duplicates()\n",
    "\n",
    "# Equalizing Data Count\n",
    "hate_df = df.query('Class == \"hate\"').sample(n=3000).copy().reset_index()\n",
    "none_df = df.query('Class == \"none\"').sample(n=3000).copy().reset_index()\n",
    "\n",
    "df = pd.merge(hate_df, none_df, how=\"outer\").copy()\n",
    "\n",
    "# DataFrame Stats\n",
    "hate_per = len(df.query('Class == \"hate\"'))/ len(df)\n",
    "none_per = len(df.query('Class == \"none\"')) / len(df)\n",
    "\n",
    "print(\"\\nLength of DataFrame:\", len(df),\"\\nPercentage of Hate Tweets:\", hate_per, \"\\nPercentage of non-Hate Tweets:\",none_per)\n",
    "\n",
    "# Split Data for SVM\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.Tweets, df.Class, test_size=0.2)\n",
    "\n",
    "# Split Data Stats\n",
    "train_hate_q = Y_train.value_counts()['hate']\n",
    "train_none_q = Y_train.value_counts()['none']\n",
    "train_len = len(Y_train)\n",
    "\n",
    "print(\"\\nLength of Train Split:\", train_len, \"\\nPercentage of Hate Tweets:\", train_hate_q / train_len, \"\\nPercentage of non-Hate Tweets:\", train_none_q / train_len)\n",
    "\n",
    "test_hate_q = Y_test.value_counts()['hate']\n",
    "test_none_q = Y_test.value_counts()['none']\n",
    "test_len = len(Y_test)\n",
    "\n",
    "print(\"\\nLength of Test Split:\", test_len, \"\\nPercentage of Hate Tweets:\", test_hate_q / test_len, \"\\nPercentage of non-Hate Tweets:\", test_none_q / test_len)\n",
    "\n",
    "# Fitting Data to SVM\n",
    "vectorizer=CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,stop_words = None,max_features = 5000)\n",
    "\n",
    "train_data_features=vectorizer.fit_transform(X_train)\n",
    "train_data_features=train_data_features.toarray()\n",
    "\n",
    "test_data_features=vectorizer.transform(X_test)\n",
    "test_data_features=test_data_features.toarray()\n",
    "\n",
    "# SVM with linear kernel\n",
    "classifier = svm.SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# Training Classifier\n",
    "print (\"\\nTraining SVM...\")\n",
    "classifier.fit(train_data_features,Y_train)\n",
    "\n",
    "# Testing Classifier\n",
    "print (\"Testing SVM...\")\n",
    "predicted = classifier.predict(test_data_features)\n",
    "\n",
    "# Show scores\n",
    "score_svm=precision_recall_fscore_support(Y_test, predicted, average='weighted')\n",
    "print(\"\\nPrecision:\", score_svm[0], \"\\nRecall:\", score_svm[1], \"\\nF1 Score:\", score_svm[2])\n",
    "\n",
    "# Re-Annotate Y_test Data\n",
    "\n",
    "test_dict = {\"Actual\" : Y_test, \"Predicted\" : predicted}\n",
    "\n",
    "# print(str(test_dict[0]))\n",
    "\n",
    "df2 = pd.DataFrame(test_dict)\n",
    "\n",
    "fn_q = len(df2.query('Actual == \"hate\" and Actual != Predicted'))\n",
    "fp_q = len(df2.query('Actual == \"none\" and Actual != Predicted'))\n",
    "\n",
    "fn_p = fn_q / len(df2)\n",
    "fp_p = fp_q / len(df2)\n",
    "\n",
    "print(\"\\nWill randomly re-annotate: \" + str((fn_p * 100)) + \"% of hate speech\\nWill randomly re-annotate: \" +  str((fp_p * 100)) + \"% of non-hate speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "hate    600\n",
      "none    600\n",
      "dtype: int64\n",
      "                                                 Tweets Class\n",
      "1996  RT @RyBen3 I'm not sexist: but I do not like t...  hate\n",
      "4384  RT @Glinner: Fuck you forever, gamergate http:...  none\n",
      "3617  Pro tip: Any time a man starts to give an opin...  none\n",
      "3334    HAHAAHAHAHHAHAHAHAH EAT SHIT KAT AND ANDRE #mkr  none\n",
      "4512  After tonight's elimination on #mkr, there's n...  none\n",
      "...                                                 ...   ...\n",
      "1513  OH SHIT HE WAS THE ONE @King0me You can call m...  hate\n",
      "2463  .@brenbarber Chemaly is a special kind of twit...  hate\n",
      "5757  RT @thetrudz: + in the fact that she is queer ...  none\n",
      "20                                 @g56yu What is that?  hate\n",
      "4652  I DONT know how I feel this way...\\r\\r\\n\\r\\r\\n...  none\n",
      "\n",
      "[1200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "l = {\"Tweets\" : X_test, \"Class\" : Y_test}\n",
    "test = pd.DataFrame(l)\n",
    "\n",
    "print(test.value_counts('Class'))\n",
    "print(test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate    600\n",
      "none    600\n",
      "Name: Class, dtype: int64\n",
      "1996    hate\n",
      "4384    none\n",
      "3617    none\n",
      "3334    none\n",
      "4512    none\n",
      "        ... \n",
      "1513    hate\n",
      "2463    hate\n",
      "5757    none\n",
      "20      hate\n",
      "4652    none\n",
      "Name: Class, Length: 1200, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test.query('Class == \"hate\"').sample(frac=fn_p).replace(\"hate\", \"none\").head()\n",
    "\n",
    "s = pd.Series(test.query('Class == \"hate\"').sample(frac = fn_p).Tweets)\n",
    "h = test.query('Class == \"none\"').sample(frac=fp_p)\n",
    "# s_t = s.Tweets.array\n",
    "h_t = h.Tweets\n",
    "\n",
    "\n",
    "# test.loc[test[\"Tweets\"] in s_t, \"Class\"] = \"none\"\n",
    "\n",
    "test.query('Tweets in @s').replace('hate', 'none')\n",
    "# test.query('Tweets in @h_t').Class.replace('none', 'hate')\n",
    "\n",
    "t = test.Class\n",
    "print(t.value_counts())\n",
    "print(t)\n",
    "\n",
    "\n",
    "# h.head()\n",
    "# test.query(\"Class in 'hate'\").head()\n",
    "\n",
    "\n",
    "# test = \n",
    "\n",
    "\n",
    "# Y_test = pd.Series(test['Class'])\n",
    "\n",
    "# test_hate_q = Y_test.value_counts()[\"hate\"]\n",
    "# test_none_q = Y_test.value_counts()[\"none\"]\n",
    "# test_len = len(Y_test)\n",
    "\n",
    "# print(\"\\nLength of Test Split:\", test_len, \"\\nPercentage of Hate Tweets:\", test_hate_q / test_len, \"\\nPercentage of non-Hate Tweets:\", test_none_q / test_len)\n",
    "\n",
    "# # Re-Testing Classifier\n",
    "# print (\"Re-Testing SVM...\")\n",
    "# r_predicted = classifier.predict(test_data_features)\n",
    "\n",
    "# # Show scores\n",
    "# score_svm=precision_recall_fscore_support(Y_test, r_predicted, average='weighted')\n",
    "# print(\"\\nPrecision:\", score_svm[0], \"\\nRecall:\", score_svm[1], \"\\nF1 Score:\", score_svm[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
